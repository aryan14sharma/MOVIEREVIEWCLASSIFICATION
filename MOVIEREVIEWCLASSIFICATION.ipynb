{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT PACKAGES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('../TextFiles/moviereviews.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking dataframes Shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250 \n",
      "\n",
      "how do films like mouse hunt get into theatres ? \r\n",
      "isn't there a law or something ? \r\n",
      "this diabolical load of claptrap from steven speilberg's dreamworks studio is hollywood family fare at its deadly worst . \r\n",
      "mouse hunt takes the bare threads of a plot and tries to prop it up with overacting and flat-out stupid slapstick that makes comedies like jingle all the way look decent by comparison . \r\n",
      "writer adam rifkin and director gore verbinski are the names chiefly responsible for this swill . \r\n",
      "the plot , for what its worth , concerns two brothers ( nathan lane and an appalling lee evens ) who inherit a poorly run string factory and a seemingly worthless house from their eccentric father . \r\n",
      "deciding to check out the long-abandoned house , they soon learn that it's worth a fortune and set about selling it in auction to the highest bidder . \r\n",
      "but battling them at every turn is a very smart mouse , happy with his run-down little abode and wanting it to stay that way . \r\n",
      "the story alternates between unfunny scenes of the brothers bickering over what to do with their inheritance and endless action sequences as the two take on their increasingly determined furry foe . \r\n",
      "whatever promise the film starts with soon deteriorates into boring dialogue , terrible overacting , and increasingly uninspired slapstick that becomes all sound and fury , signifying nothing . \r\n",
      "the script becomes so unspeakably bad that the best line poor lee evens can utter after another run in with the rodent is : \" i hate that mouse \" . \r\n",
      "oh cringe ! \r\n",
      "this is home alone all over again , and ten times worse . \r\n",
      "one touching scene early on is worth mentioning . \r\n",
      "we follow the mouse through a maze of walls and pipes until he arrives at his makeshift abode somewhere in a wall . \r\n",
      "he jumps into a tiny bed , pulls up a makeshift sheet and snuggles up to sleep , seemingly happy and just wanting to be left alone . \r\n",
      "it's a magical little moment in an otherwise soulless film . \r\n",
      "a message to speilberg : if you want dreamworks to be associated with some kind of artistic credibility , then either give all concerned in mouse hunt a swift kick up the arse or hire yourself some decent writers and directors . \r\n",
      "this kind of rubbish will just not do at all . \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking a sample of review\n",
    "print(len(df['review'][0]),'\\n')\n",
    "print(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1965, 2)\n"
     ]
    }
   ],
   "source": [
    "#Dropping Null Values\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
     ]
    }
   ],
   "source": [
    "#Dropping reviews which contain only whitespaces\n",
    "#First declare a array\n",
    "blanks=[]\n",
    "#Now itertuples returns all three column iterators.Therefoe i,lb and rv as used for iteration.\n",
    "for i,lb,rv in df.itertuples():\n",
    "    if type(rv)==str: #checking whether it is not null\n",
    "        if rv.isspace()==True:#now if contains only whitespace\n",
    "            blanks.append(i)#appending on array\n",
    "print(blanks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1938, 2)\n"
     ]
    }
   ],
   "source": [
    "#removing blank spaces\n",
    "df.drop(blanks,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    969\n",
       "neg    969\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking value counts of label\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data in train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=df['review']\n",
    "y=df['label']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pipepline to use TFIDF with Navie Bayes and SVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_class_nb=Pipeline([('Tfidf',TfidfVectorizer()),('Naive_Bayes',MultinomialNB())])\n",
    "text_class_svm=Pipeline([('Tfidf',TfidfVectorizer()),('SVM',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('Tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting \n",
    "text_class_nb.fit(x_train,y=y_train)\n",
    "text_class_svm.fit(x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forming Prediction\n",
    "prediction_nb=text_class_nb.predict(x_test)\n",
    "prediction_svm=text_class_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The confusion matrix of NB is \n",
      " [[287 130]\n",
      " [ 21 202]]\n",
      "\n",
      "\n",
      "The classification report of NB \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.93      0.69      0.79       417\n",
      "        pos       0.61      0.91      0.73       223\n",
      "\n",
      "avg / total       0.82      0.76      0.77       640\n",
      "\n",
      "\n",
      "\n",
      " Accuracy Score NB 76.40625 %\n",
      "\n",
      "\n",
      "The confusion matrix of SVM is \n",
      " [[259  49]\n",
      " [ 49 283]]\n",
      "\n",
      "\n",
      "The classification report of SVM \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.84      0.84      0.84       308\n",
      "        pos       0.85      0.85      0.85       332\n",
      "\n",
      "avg / total       0.85      0.85      0.85       640\n",
      "\n",
      "\n",
      "\n",
      " Accuracy Score SVM 84.6875 %\n"
     ]
    }
   ],
   "source": [
    "#PRINTING the confusion matrix ,classification report and accuracy score\n",
    "from sklearn import metrics\n",
    "print('\\nThe confusion matrix of NB is \\n',metrics.confusion_matrix(prediction_nb,y_test))\n",
    "print('\\n\\nThe classification report of NB \\n',metrics.classification_report(prediction_nb,y_test))\n",
    "print('\\n\\n Accuracy Score NB',metrics.accuracy_score(prediction_nb,y_test)*100,'%')\n",
    "print('\\n\\nThe confusion matrix of SVM is \\n',metrics.confusion_matrix(prediction_svm,y_test))\n",
    "print('\\n\\nThe classification report of SVM \\n',metrics.classification_report(prediction_svm,y_test))\n",
    "print('\\n\\n Accuracy Score SVM',metrics.accuracy_score(prediction_svm,y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The confusion matrix of NB is \n",
      " [[274  94]\n",
      " [ 34 238]]\n",
      "\n",
      "\n",
      "The classification report of NB \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.74      0.81       368\n",
      "        pos       0.72      0.88      0.79       272\n",
      "\n",
      "avg / total       0.82      0.80      0.80       640\n",
      "\n",
      "\n",
      "\n",
      " Accuracy Score NB 80.0 %\n",
      "\n",
      "\n",
      "The confusion matrix of SVM is \n",
      " [[252  52]\n",
      " [ 56 280]]\n",
      "\n",
      "\n",
      "The classification report of SVM \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.82      0.83      0.82       304\n",
      "        pos       0.84      0.83      0.84       336\n",
      "\n",
      "avg / total       0.83      0.83      0.83       640\n",
      "\n",
      "\n",
      "\n",
      " Accuracy Score SVM 83.125 %\n"
     ]
    }
   ],
   "source": [
    "#Now as we didn't use Stopwords in TFIDFVectorizer \n",
    "\n",
    "#Now we use stopwords\n",
    "\n",
    "text_class_nb=Pipeline([('Tfidf',TfidfVectorizer(stop_words='english')),('Naive_Bayes',MultinomialNB())])\n",
    "text_class_svm=Pipeline([('Tfidf',TfidfVectorizer(stop_words='english')),('SVM',LinearSVC())])\n",
    "\n",
    "#Fitting\n",
    "\n",
    "text_class_nb.fit(x_train,y=y_train)\n",
    "text_class_svm.fit(x_train,y=y_train)\n",
    "\n",
    "#Forming Prediction\n",
    "\n",
    "prediction_nb=text_class_nb.predict(x_test)\n",
    "prediction_svm=text_class_svm.predict(x_test)\n",
    "\n",
    "#PRINTING the confusion matrix ,classification report and accuracy score\n",
    "\n",
    "from sklearn import metrics\n",
    "print('\\nThe confusion matrix of NB is \\n',metrics.confusion_matrix(prediction_nb,y_test))\n",
    "print('\\n\\nThe classification report of NB \\n',metrics.classification_report(prediction_nb,y_test))\n",
    "print('\\n\\n Accuracy Score NB',metrics.accuracy_score(prediction_nb,y_test)*100,'%')\n",
    "print('\\n\\nThe confusion matrix of SVM is \\n',metrics.confusion_matrix(prediction_svm,y_test))\n",
    "print('\\n\\nThe classification report of SVM \\n',metrics.classification_report(prediction_svm,y_test))\n",
    "print('\\n\\n Accuracy Score SVM',metrics.accuracy_score(prediction_svm,y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we saw using stop_words filter increased Accuracy Score in NB from 76.4% to 80.0% \n",
    "### But decreased SVM Accuracy _Score from  84.6% to 83.125%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now using it check my own written Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review=\"Movie was not what i expected from Christopher NOlan Movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT FROM NB \n",
      "['neg']\n",
      "\n",
      "\n",
      "SENTIMENT FROM SVM\n",
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "print('SENTIMENT FROM NB ')\n",
    "print(text_class_nb.predict([my_review]))   \n",
    "print('\\n\\nSENTIMENT FROM SVM')\n",
    "print(text_class_svm.predict([my_review]))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
